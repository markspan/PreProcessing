{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66299b77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing Cheat Sheet\n",
    "```PSMCV-2.2022-2023.1```\n",
    "\n",
    "Authors: \n",
    "- Robbert van der Mijn, w.r.van.der.mijn@rug.nl, 2022\n",
    "- Mark Span, m.m.span@rug.nl, 2024\n",
    "\n",
    "This notebook serves as a comprehensive guide for preprocessing scripts commonly used in data analysis. The scripts provided here aim to facilitate various preprocessing tasks, ensuring data is clean and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d13c2-b59a-4c98-95a4-778c16add04e",
   "metadata": {},
   "source": [
    "## Modules and Packages\n",
    "\n",
    "This section outlines the necessary modules and packages required for the preprocessing tasks. Ensure that all these packages are installed in your environment.\n",
    "\n",
    "- **eyelinkparser**: A package for parsing EyeLink data files.\n",
    "- **datamatrix**: A library for working with data matrices, providing functionality for data manipulation and analysis.\n",
    "- **fastnumbers**: A module for fast and safe conversion of strings to numbers.\n",
    "- **numpy**: A fundamental package for numerical computations in Python.\n",
    "- **scipy**: A library used for scientific and technical computing.\n",
    "- **prettytable**: A module to create ASCII tables in Python.\n",
    "- **openpyxl**: A library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files.\n",
    "- **json-tricks**: A library for handling JSON files with additional features.\n",
    "- **tomlkit**: A library for TOML file parsing.\n",
    "- **psutil**: A cross-platform library for accessing system details and process utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad34982-86c4-4b33-b00c-1aeb56ebe0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the eyelinkparser package which is used for parsing EyeLink data files.\n",
    "!pip install eyelinkparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7c5b5-e133-418d-83db-94d227e5d62d",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "This section covers the steps required to load the data into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453eec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datamatrix is also from Sebastiaan. You need a conveinient method to manage all your data...\n",
    "\n",
    "from datamatrix import (\n",
    "    plot,\n",
    "    operations as ops,\n",
    "    series as srs,\n",
    "    functional as fnc,\n",
    "    SeriesColumn,\n",
    ")\n",
    "from eyelinkparser import parse, defaulttraceprocessor\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "# This is a really helpfull library if you want to combine the use of R and Python.\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f27b13-a3ef-4394-bcdd-85bc251aad68",
   "metadata": {},
   "source": [
    "## Declaring a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3783dc22-66a1-422b-8a7a-12232e52268d",
   "metadata": {},
   "source": [
    "The eyelinkparser needs info from you on what your trials look like. Therefore you need to write a function that reads in your trials and define its structure in there. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocessor():\n",
    "    \n",
    "    dm = parse(\n",
    "        traceprocessor = defaulttraceprocessor(\n",
    "          blinkreconstruct = True,\n",
    "          mode= 'advanced',\n",
    "          downsample = None\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # define the max depth manually: baseline, problem, fixation, response and feedback\n",
    "    MAX_DEPTH = 1500 + 800 + 2500 + 2000 \n",
    "\n",
    "    # get the current max depth, we'll be cutting it off later\n",
    "    max_depth = dm.ptrace_baseline.depth + dm.ptrace_problem.depth + dm.ptrace_fixation.depth + dm.ptrace_response.depth + dm.ptrace_feedback.depth\n",
    "\n",
    "    # Create new series column that will hold our new pupil trace\n",
    "    dm.pupil = SeriesColumn(depth = max_depth)\n",
    "\n",
    "    # For each trial, trim pupil traces based on the nan values in the time trace (there are more elegant solutions I'm sure)\n",
    "    for i, row in enumerate(dm):\n",
    "        ptrace_baseline = row.ptrace_baseline[~np.isnan(row.ttrace_baseline)]\n",
    "        ptrace_problem = row.ptrace_problem[~np.isnan(row.ttrace_problem)]\n",
    "        ptrace_fixation = row.ptrace_fixation[~np.isnan(row.ttrace_fixation)]\n",
    "        ptrace_response = row.ptrace_response[~np.isnan(row.ttrace_response)]\n",
    "        ptrace_feedback = row.ptrace_feedback[~np.isnan(row.ttrace_feedback)]\n",
    "        \n",
    "        # Concatenate and pad so they're all the same depth\n",
    "        pupil = np.concatenate((ptrace_baseline, ptrace_problem, ptrace_fixation, ptrace_response, ptrace_feedback))\n",
    "        pupil = np.pad(pupil, (0, max_depth - len(pupil)), \"constant\", constant_values = np.nan)\n",
    "        \n",
    "        # Write this trial to the original dm\n",
    "        dm.pupil[i] = pupil\n",
    "        \n",
    "    # Trim the original dm to our manual depth (the feedback phase of some of the really long trials will be cut off)\n",
    "    dm.pupil.depth = MAX_DEPTH\n",
    "    # and return only the data we want to analyse. \n",
    "    dm = dm[(\"subject_nr\", \"pupil\", \"count_trial_sequence\", \"correct\", \"difficulty\", \"practice\")]\n",
    "    \n",
    "    return dm\n",
    "\n",
    "# my_preprocessor.clear() # you can run this line to clear the stored output of the function\n",
    "dm = my_preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639673ca-0f5f-469f-ab44-3599a97afaf6",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "In this example, the data cleaning is automated. This is not always possible, and therefore this placeholder title is inserted. If needed: Clean your data here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad544b-aa42-4019-83f4-c3a7d96960d9",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "This section provides methods for visualizing the data to gain insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae43eb1-9fa6-418b-9d72-3e55bc034f83",
   "metadata": {},
   "source": [
    "### Saving plots as pngs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc12609-11ca-473d-8a67-017fc71b4fad",
   "metadata": {},
   "source": [
    "We use MatPlotLib for plotting here. There is sometimes an issue with the fonts matplotlib defaults to. Hopefully this is a fix for that. If you have many warnings about fonts, please let me know..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f11ca-283b-4f22-a755-f581e9bb7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager\n",
    "matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "\n",
    "mpl.rcParams['font.family'] = \"sans-serif\"\n",
    "mpl.rcParams['font.sans-serif'] = \"DejaVu Sans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24265ca2-0995-41fe-bb37-44c5c2dd726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dm.pupil[0], color = \"black\")\n",
    "plt.ylim(300, 2700)\n",
    "plt.savefig('single_trial.png', bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "for row in dm:    \n",
    "    plt.plot(row.pupil, alpha = .1, color = \"black\")\n",
    "plt.ylim(300, 2700)\n",
    "plt.savefig('all_trials.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
