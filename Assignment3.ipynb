{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cebab62-ce01-4321-a2b0-e5a0ae80b131",
   "metadata": {},
   "source": [
    "# Data Collection and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66299b77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 3: Preprocessing\n",
    "\n",
    "This assignment will take you through some of the required steps for preprocessing your own data later on. \n",
    "\n",
    "Here, we'll use the data we collected during the demonstration experiment (hint: open up the experiment once more to check out the durations of all the phases)\n",
    "\n",
    "You'll to this assignment individually on you own computer (or one of the university computers). \n",
    "\n",
    "You are likely to run into many errors. THIS IS NORMAL. A big part of scientific computing is solving problems. Sometimes, when you enter one of your error messages into google, you will not get a solution to your problem. Ask us for help early! Asking the correct question is hard!\n",
    "\n",
    "You can sequentially run the chunks of code in this script and they will gradually take you through the preprocessing of our demo data. Sometimes you are asked to fill in some code (it will be marked with #TODO) and sometimes you are asked to interpret output using text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b97f46-ad05-4324-bfac-e8e0bb44c575",
   "metadata": {},
   "source": [
    "```PSMCV-2.2024-2025.1```\n",
    "\n",
    "Authors: \n",
    "- Robbert van der Mijn, w.r.van.der.mijn@rug.nl, 2022\n",
    "- Mark Span, m.m.span@rug.nl, 2024\n",
    "\n",
    "See also the tutorial at: https://pydatamatrix.eu/1.0/eyelinkparser/\n",
    "\n",
    "_and:_\n",
    "\n",
    "[A very similar explanation by Sebastiaan](https://youtu.be/PtUmhQ2vupw?t=1)\n",
    "\n",
    "_and definitely:_\n",
    "\n",
    "Mathôt S, Vilotijević A. Methods in cognitive pupillometry: Design, preprocessing, and statistical analysis. Behav Res Methods. 2023 Sep;55(6):3055-3077. doi: 10.3758/s13428-022-01957-7. Epub 2022 Aug 26. PMID: 36028608; PMCID: PMC10556184.\n",
    "\n",
    "### Additional References\n",
    "\n",
    "Kahneman, D., & Beatty, J. (1966). Pupil diameter and load on memory. Science, 154(3756), 1583–1585. https://doi.org/10.1126/science.154.3756.1583\n",
    "\n",
    "Mathôt, S., (2018). Pupillometry: Psychology, Physiology, and Function. Journal of Cognition. 1(1), p.16. https://doi.org/10.5334/joc.18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519d902-60ff-45a1-93ec-97184bf4bde1",
   "metadata": {},
   "source": [
    "Some of these modules are not installed by default with Python in your computer, install them first. This syntax will (try to) do so if needed. There is no need for you to understand how this works (yet..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7390b-b637-44db-8f09-c2170a9a522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import gdown  \n",
    "except ImportError:\n",
    "    print(\"Installing GDOWN\")\n",
    "    !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badf065-e98e-4f85-b478-f1ecf2a59b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import eyelinkparser  \n",
    "except ImportError:\n",
    "    print(\"Installing eyelinkparser\")\n",
    "    !pip install eyelinkparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083dfd86-9547-455f-935a-a75af49177ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import time_series_test\n",
    "except ImportError:\n",
    "    print(\"Installing time_series_test\")\n",
    "    !pip install time_series_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a06bd-ebb4-4f53-9462-0ef6291886d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import datamatrix\n",
    "except ImportError:\n",
    "    print(\"Installing datamatrix\")\n",
    "    !pip install datamatrix==1.0.13 -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0132b1-11e9-42d6-8de9-2a4dd8e8acf9",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "First we will download data that we collected before: this is data from the demo-experiment I have shown in earlier meetings...\n",
    "\n",
    "The data will be downloaded to a directory named \"data\", that will be created in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13ecd2-c62e-419a-843f-3f431193ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "url = r'https://drive.google.com/drive/folders/1aJSK0F6vaN-scfkr1xExg3x_FRK8Gd9B'\n",
    "gdown.download_folder(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c3dd2-d242-42ff-9dbb-6ab385da5bbc",
   "metadata": {},
   "source": [
    "It is common to start your analysis script with loading modules you will use later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453eec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamatrix import (\n",
    "    plot,\n",
    "    operations as ops,\n",
    "    series as srs,\n",
    "    functional as fnc,\n",
    "    SeriesColumn,\n",
    ")\n",
    "from eyelinkparser import parse, defaulttraceprocessor\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager\n",
    "\n",
    "# This is to get rid of some warnings while plotting, telling us we don't have the correct fonts installed.\n",
    "matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "mpl.rcParams['font.family'] = \"sans-serif\"\n",
    "mpl.rcParams['font.sans-serif'] = \"DejaVu Sans\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1b3ef",
   "metadata": {},
   "source": [
    "The following lines define our own custom function that we can use to get our data from the folder called \"data\". It wraps around the \"parse\" function which comes with eyelinkparser and returns its result. The first time you run it, it will take some time. The memoize decorator makes sure that the result is stored on your computer, so it will be much faster the second time. \n",
    "\n",
    "See that we will not use the \"automatic blinkreconstruction\". This is for demonstration purposed: the automatic, \"advanced\" blinkreconstruction __is__ the preferred option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe9c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@fnc.memoize(persistent=True)\n",
    "def get_data():\n",
    "    \n",
    "    dm = parse(\n",
    "        traceprocessor = defaulttraceprocessor(\n",
    "          blinkreconstruct = False, \n",
    "          downsample = None\n",
    "        )\n",
    "    )\n",
    "    return dm\n",
    "\n",
    "#get_data.clear() # you can run this line to clear the stored output of the function\n",
    "dm = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ea3c9",
   "metadata": {},
   "source": [
    "Great! We have now a data table containing the data of all participants. \n",
    "\n",
    "Let's inspect the information we have in our data table. Can you think of some useful statements to inspect what variables there are in a data table. hint: check out the cheat sheet on https://datamatrix.cogsci.nl/\n",
    "\n",
    "ASSIGNMENT: \n",
    "\n",
    "    - Print all the column names to the console\n",
    "    \n",
    "    - Print out the the colums named \"subject_nr\" and \"ptrace_fixation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9156cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc234b6c",
   "metadata": {},
   "source": [
    "Those are quite some columns! Some of these colums are not very interesting to us, so we'll get rid of them momentarily. \n",
    "\n",
    "Each row in this table contains the information about a single trial. In this demo, each pp did 44 trials. \n",
    "\n",
    "ASSIGNMENT: \n",
    "\n",
    "    - Confirm this by printing the number of rows in this table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed59b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7110f",
   "metadata": {},
   "source": [
    "When you printed the whole column \"subject_nr\" it listed for each trial to which pp that trial belongs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1773c3",
   "metadata": {},
   "source": [
    "During each trial, we've been sending messages at the start and end of phases.\n",
    "\n",
    "ASSIGNMENT:  \n",
    "\n",
    "    - List the phases here in the correct order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3bdab",
   "metadata": {},
   "source": [
    "The continuous data of each phase (e.g., pupil size, gaze coordinates) are stored as SeriesColumns. For example, each cell of the column \"ptrace_response\" contains a collection of pupil sizes for that particular trial, during the response phase. \n",
    "\n",
    "Most phases are always exactly the same duration (the \"problem\" phase is always exactly 800ms). But, some phases have variable duration (\"response\" just ends when the pp presses a button). However, any SeriesColumn must always be a particular \"depth\" (think of our table as a \"3d\" table; a matrix). Its depth will always be the same depth as the longest trial, but the values will be padded with a special type of data: \"nan\" (\"not a number\").\n",
    "\n",
    "We use a little trick to concatenate (basically \"paste\") the phases together. Don't worry about the details of this procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3caa080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocessor():\n",
    "    \n",
    "    dm = parse(\n",
    "        traceprocessor = defaulttraceprocessor(\n",
    "          blinkreconstruct = False,\n",
    "          mode = 'advanced',\n",
    "          downsample = None\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # define the max depth manually: baseline, problem, fixation, response and feedback\n",
    "    MAX_DEPTH = 1500 + 800 + 2500 + 2000 \n",
    "\n",
    "    # get the current max depth, we'll be cutting it off later\n",
    "    max_depth = dm.ptrace_baseline.depth + dm.ptrace_problem.depth + dm.ptrace_fixation.depth + dm.ptrace_response.depth + dm.ptrace_feedback.depth\n",
    "\n",
    "    # Create new series column that will hold our new pupil trace\n",
    "    dm.pupil = SeriesColumn(depth = max_depth)\n",
    "\n",
    "    # For each trial, trim pupil traces based on the nan values in the time trace (there are more elegant solutions I'm sure)\n",
    "    for i, row in enumerate(dm):\n",
    "        ptrace_baseline = row.ptrace_baseline[~np.isnan(row.ttrace_baseline)]\n",
    "        ptrace_problem  = row.ptrace_problem[~np.isnan(row.ttrace_problem)]\n",
    "        ptrace_fixation = row.ptrace_fixation[~np.isnan(row.ttrace_fixation)]\n",
    "        ptrace_response = row.ptrace_response[~np.isnan(row.ttrace_response)]\n",
    "        ptrace_feedback = row.ptrace_feedback[~np.isnan(row.ttrace_feedback)]\n",
    "        \n",
    "        # Concatenate and pad so they're all the same depth\n",
    "        pupil = np.concatenate((ptrace_baseline, ptrace_problem, ptrace_fixation, ptrace_response, ptrace_feedback))\n",
    "        pupil = np.pad(pupil, (0, max_depth - len(pupil)), \"constant\", constant_values = np.nan)\n",
    "        \n",
    "        # Write this trial to the original dm\n",
    "        dm.pupil[i] = pupil\n",
    "        \n",
    "    # Trim the original dm to our manual depth (the feedback phase of some of the really long trials will be cut off)\n",
    "    dm.pupil.depth = MAX_DEPTH\n",
    "    # and return only the data we want to analyse. \n",
    "    dm = dm[(\"subject_nr\", \"pupil\", \"count_trial_sequence\", \"correct\", \"difficulty\", \"practice\", \"response_time\")]\n",
    "    \n",
    "    return dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d41a75",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32051827",
   "metadata": {},
   "source": [
    "From the matplotlib package we've imported pyplot (as plt), from which we can now use the plot function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the very first trial (python starts counting at 0)\n",
    "plt.figure() # creates a \"new\" figure\n",
    "plt.plot(dm.pupil[0], color = \"black\")\n",
    "\n",
    "# Another way to create a subset (in this case we create a new dm that holds the 3rd trial of pp 3)\n",
    "subdm = (dm.subject_nr == 3) & (dm.count_trial_sequence == 2)\n",
    "plt.figure()\n",
    "plt.plot(subdm.pupil[0], color = \"black\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf084138",
   "metadata": {},
   "source": [
    "ASSIGNMENT: \n",
    "\n",
    "    - plot two more trials with a blink (play around with subsetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a659e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33ef74",
   "metadata": {},
   "source": [
    "## Blink reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2fb5d",
   "metadata": {},
   "source": [
    "When a pp blinks, data recorded during that period is missing or distorted.\n",
    "\n",
    "We use srs.blinkreconstruct to create a new trace in which these are restored. \n",
    "\n",
    "For now, we'll call the column \"pupil_reconstructed\". In practice, you would overwrite the original one, or use a more practical (i.e., short) name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b278949",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.pupil_reconstructed = srs.blinkreconstruct(dm.pupil, mode = \"advanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f413a",
   "metadata": {},
   "source": [
    "Lets visualise how that reconstruction works.\n",
    "\n",
    "We can plot the two traces simultaniously. We'll color the original one red (\"alpha = .5\" will also make it a bit \"see through\"). In most trials, the pp will not have blinked. See if those blinks you found in the previous assignment were interpolated correctly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fe3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_nr = 1\n",
    "plt.figure()\n",
    "plt.plot(dm.pupil_reconstructed[row_nr], color = \"black\")\n",
    "plt.plot(dm.pupil[row_nr], color = \"red\", alpha = .5)\n",
    "plt.title(row_nr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6274aa7",
   "metadata": {},
   "source": [
    "srs.blinkreconstruction accepts a number of parameters that might change its functioning. \n",
    "\n",
    "ASSIGNMENT:\n",
    "\n",
    "   In your own words, describe what the following do:\n",
    "    \n",
    "    - vt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471be8e",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc40e74",
   "metadata": {},
   "source": [
    "    - margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349420f0",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1152818",
   "metadata": {},
   "source": [
    "    - smooth_winlen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f71a82",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19f5369",
   "metadata": {},
   "source": [
    "### Overwrite raw pupil data\n",
    "Now we overwrite our raw pupil column with the reconstructed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.pupil = dm.pupil_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be5464",
   "metadata": {},
   "source": [
    "## Averaging part 1\n",
    "\n",
    "Our goal is to analyse the average pupil size. For example, to compare mean pupil sizes between two conditions. \n",
    "\n",
    "Do do so, we have two imporant steps ahead of us: \n",
    "    - Time Locking\n",
    "    - Baselining\n",
    "    \n",
    "The next figures will illustrate why these are crucial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdf2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colors of the conditions\n",
    "CON_COLS = {\"easy\": \"blue\", \"hard\": \"red\"}\n",
    "# for each pp, start a new figure\n",
    "for s, subdm in ops.split(dm.subject_nr):    \n",
    "    plt.figure()\n",
    "    # now split up the table into two tables, the hard trials and the easy trials\n",
    "    for c, cdm in ops.split(subdm.difficulty):\n",
    "        # for each of those split up tables, go over each trial and plot the line\n",
    "        for row in cdm:\n",
    "            plt.plot(row.pupil, color = CON_COLS[c], alpha = .3)\n",
    "    # Finally, for each figure, create a title and legend\n",
    "    plt.title(\"pp {}\".format(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f324aa2",
   "metadata": {},
   "source": [
    "That's quite messy!\n",
    "\n",
    "We're expecting the red lines to be higher than blue lines. But if that difference exists, it's currently lost in intertrial variation (noise).\n",
    "\n",
    "Let's use the plot.trace function anyway to average all these traces (we'll actually already see a difference!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81250c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON_COLS = {\"easy\": \"blue\", \"hard\": \"red\"}\n",
    "plt.figure()\n",
    "for c, cdm in ops.split(dm.difficulty):\n",
    "    # Notice that plot.trace is a different function than plt.plot! This one can accept a whole bunch of trials, calculated the average and sd at each time point and then plots it for us.\n",
    "    plot.trace(cdm.pupil, color = CON_COLS[c], label = c, alpha = .3)\n",
    "# create a legend\n",
    "plt.legend(frameon = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391079b",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Next step: Baselining!\n",
    "\n",
    "We expect the difference between conditions during the baseline period (in our case, the 1500 ms before we start showing the problem) is due to noise. So we subtract the average pupil size during a short baseline window of each trial from all the other pupil values. In our case, we'll use the period between 1480 ms and 1500 ms to calculate the baseline. \n",
    "\n",
    "srs.baseline creates a new trace in in which exactly that is done. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ba76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.pupil_baselined = srs.baseline(dm.pupil, dm.pupil, bl_start = 1480, bl_end = 1500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d92480a",
   "metadata": {},
   "source": [
    "## Averaging part 2\n",
    "\n",
    "Now do the exact same visualisation as earlier, but now with the baselined traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4821d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON_COLS = {\"easy\": \"blue\", \"hard\": \"red\"}\n",
    "for s, subdm in ops.split(dm.subject_nr):    \n",
    "    plt.figure()\n",
    "    for c, cdm in ops.split(subdm.difficulty):\n",
    "        for row in cdm:\n",
    "            plt.plot(row.pupil_baselined, color = CON_COLS[c], alpha = .3)\n",
    "    plt.title(\"pp {}, baselined\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a99900",
   "metadata": {},
   "source": [
    "ASSIGNMENT: \n",
    "\n",
    "    - Explain in your own words why we see this \"bow tie\"-like figure\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce87f3",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb99452",
   "metadata": {},
   "source": [
    "And again, we can use plot.trace to visualise the means, compare this figure top the non-baselined figure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON_COLS = {\"easy\": \"blue\", \"hard\": \"red\"}\n",
    "plt.figure()\n",
    "for c, cdm in ops.split(dm.difficulty):\n",
    "    plot.trace(cdm.pupil_baselined, color = CON_COLS[c], label = c, alpha = .3)\n",
    "plt.legend(frameon = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec232a",
   "metadata": {},
   "source": [
    "That looks quite nice! \n",
    "\n",
    "ASSIGNMENT: \n",
    "\n",
    "    - Why do you think the line becomes all jittery after about 6,5 seconds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c8865",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb6686",
   "metadata": {},
   "source": [
    "### Time Lock \n",
    "(not neccesary for this demo, but could be crucial for you later!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367703e",
   "metadata": {},
   "source": [
    "Baselining only works when your traces are time locked. In our demo, the problem is always shown at timepoint 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496df6d",
   "metadata": {},
   "source": [
    "### Downsample\n",
    "In this demo, we've recorded pupil size at 1000Hz. Each sample represents a snapshot of the pupil size for the next millisecond. \n",
    "\n",
    "But, changes in pupil size from 1ms to the next are unlikely to reflect a cognitive function in which we're interested. Pupil responses are much slower. Therefore, to reduce the amount of data we store, we downsample to a lower frequency. \n",
    "\n",
    "We could just take every 10th sample and call it a day. But that could lead to aliasing. Instead, we take every 10th sample, but replace it with the mean of the 10 surrounding samples. srs.downsample helps you with this. Here, we'll visualize the effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccdb72",
   "metadata": {},
   "source": [
    "First determine the inter sample duration (verify that this is 1 ms, because we sampled at 1000Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9766721",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPDUR = dm.ttrace_baseline[1, 1] - dm.ttrace_baseline[1, 0]\n",
    "\n",
    "print(SAMPDUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fbd52",
   "metadata": {},
   "source": [
    "ASSIGNMENT: \n",
    "\n",
    "    - What would SAMPDUR have been if we'd set the Eyelink to sample at 250 Hz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315c330",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e530230",
   "metadata": {},
   "source": [
    "Let's determine that we want to downsample by a factor of 10 (i.e., 1000Hz becomes 100Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ae6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a92856",
   "metadata": {},
   "source": [
    "Let's plot the first 300 samples (i.e., 300ms) of the very first trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51339e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUR = 300\n",
    "pupil = dm.pupil[0, :DUR]\n",
    "time = np.arange(DUR) # will be a vector of time points (x axis)\n",
    "plt.figure()\n",
    "plt.plot(time, pupil, \"-\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Pupil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce6c35",
   "metadata": {},
   "source": [
    "Nothing special so far\n",
    "\n",
    "Now take that same segment, downsample it and plot both in one figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1283e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_ds = srs.downsample(dm.pupil[0, :DUR], DS)\n",
    "time_ds = np.arange((DS * SAMPDUR)/2, DUR, step = DS * SAMPDUR) # a new time vector must also be created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7777e44",
   "metadata": {},
   "source": [
    "Using the arange function, we created a new vector of the exact same lengths as the pupil trace. The number represent the time points at which those pupil sizes were recorded. \n",
    "\n",
    "So we start counting at 0, up to the duration of the trace (\"DUR\"), with steps of the original inter sample duration multiplied with the downsample factor.\n",
    "\n",
    "And to make this even more complicated, we don't acturally start counting at 0, but down half a sample duration further: \"(DS * SAMPDUR)/2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time, pupil, \"-\")\n",
    "plt.plot(time_ds, pupil_ds, \"-\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Pupil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afb35f",
   "metadata": {},
   "source": [
    "ASSIGNMENT: \n",
    "\n",
    "    - How many datapoints are in pupil, and in pupil_ds? hint: use pythons \"len\" function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a2bba",
   "metadata": {},
   "source": [
    "Let's look a little closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8064855",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOM_IN = 60\n",
    "plt.figure()\n",
    "plt.plot(time[:ZOOM_IN], pupil[:ZOOM_IN], \"-\", color = \"blue\")\n",
    "plt.plot(time[:ZOOM_IN], pupil[:ZOOM_IN], \".\", color = \"blue\", ms = 10)\n",
    "plt.plot(time_ds[:int(ZOOM_IN/DS)], pupil_ds[:int(ZOOM_IN/DS)], \"-\", color = \"red\")\n",
    "plt.plot(time_ds[:int(ZOOM_IN/DS)], pupil_ds[:int(ZOOM_IN/DS)], \".\", color = \"red\", ms = 10)\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Pupil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c2c35",
   "metadata": {},
   "source": [
    "#### Apply downsampling\n",
    "\n",
    "Above, we only applied downsampling to a small segment of our data. \n",
    "Now, we apply it to the whole pupil trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7847031",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Samples per trial before downsampling: {}\".format(dm.pupil.depth))\n",
    "dm.pupil = srs.downsample(dm.pupil, by = 10)\n",
    "print(\"Samples per trial after downsampling: {}\".format(dm.pupil.depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b5cc2",
   "metadata": {},
   "source": [
    "### Reducing file size \n",
    "\n",
    "Before putting the whole pipeline together to run the preprocessing, we make sure to only store the data that we know we'll use later for the analysis. Therefore, go back to the assignment where you printed all the column names and determine which ones you want to keep.\n",
    "\n",
    "ASSIGNMENT: \n",
    "\n",
    "    - Keep only the columns you think are neccesary for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1be2f3",
   "metadata": {},
   "source": [
    "Here's an example on how to only keep these three columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_small = dm[(\"subject_nr\", \"pupil\", \"count_trial_sequence\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e149878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d247ec2",
   "metadata": {},
   "source": [
    "\n",
    "## Creating your own pipeline\n",
    "You now know all the ingredients to create your own pipeline function that parses the raw data files, and does your preprocessing. \n",
    "\n",
    "This function looks kinda similar to the one we used earlier in this assignment. It's now your job to find all the crucial pieces and add them to our final function: \"my_preprocessor()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "@fnc.memoize(persistent=True)\n",
    "def my_preprocessor():\n",
    "    \n",
    "    dm = parse(\n",
    "        traceprocessor = defaulttraceprocessor(\n",
    "          blinkreconstruct = False, \n",
    "          downsample = None,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # define the max depth manually: baseline, problem, fixation, response and feedback\n",
    "    MAX_DEPTH = 1500 + 800 + 2500 + 2000 \n",
    "\n",
    "    # get the current max depth, we'll be cutting it off later\n",
    "    max_depth = dm.ptrace_baseline.depth + dm.ptrace_problem.depth + dm.ptrace_fixation.depth + dm.ptrace_response.depth + dm.ptrace_feedback.depth\n",
    "\n",
    "    # Create new series column that will hold our new pupil trace\n",
    "    dm.pupil = SeriesColumn(depth = max_depth)\n",
    "\n",
    "    # For each trial, trim pupil traces based on the nan values in the time trace (there are more elegant solutions I'm sure)\n",
    "    for i, row in enumerate(dm):\n",
    "        ptrace_baseline = row.ptrace_baseline[~np.isnan(row.ttrace_baseline)]\n",
    "        ptrace_problem = row.ptrace_problem[~np.isnan(row.ttrace_problem)]\n",
    "        ptrace_fixation = row.ptrace_fixation[~np.isnan(row.ttrace_fixation)]\n",
    "        ptrace_response = row.ptrace_response[~np.isnan(row.ttrace_response)]\n",
    "        ptrace_feedback = row.ptrace_feedback[~np.isnan(row.ttrace_feedback)]\n",
    "        \n",
    "        # Concatenate and pad so they're all the same depth\n",
    "        pupil = np.concatenate((ptrace_baseline, ptrace_problem, ptrace_fixation, ptrace_response, ptrace_feedback))\n",
    "        pupil = np.pad(pupil, (0, max_depth - len(pupil)), \"constant\", constant_values = np.nan)\n",
    "        \n",
    "        # Write this trial to the original dm\n",
    "        dm.pupil[i] = pupil\n",
    "        \n",
    "    # Trim the original dm to our manual depth (the feedback phase of some of the really long trials will be cut off)\n",
    "    dm.pupil.depth = MAX_DEPTH\n",
    "    \n",
    "    dm.pupil = srs.baseline(dm.pupil, dm.pupil, bl_start = 1480, bl_end = 1500)\n",
    "    \n",
    "    SAMPDUR = dm.ttrace_baseline[1, 1] - dm.ttrace_baseline[1, 0]\n",
    "    DS = 10\n",
    "    \n",
    "    dm.pupil = srs.downsample(dm.pupil, by = DS)\n",
    "    \n",
    "    dm.time = SeriesColumn(dm.pupil.depth)\n",
    "    dm.time = np.arange((DS * SAMPDUR)/2, dm.pupil.depth * (DS/SAMPDUR), step = DS * SAMPDUR) # a new time vector must also be created\n",
    "\n",
    "    dm = dm[(\"subject_nr\", \"pupil\", \"time\", \"count_trial_sequence\", \"correct\", \"difficulty\", \"practice\")]\n",
    "    \n",
    "    return dm\n",
    "\n",
    "my_preprocessor.clear() # you can run this line to clear the stored output of the function\n",
    "dm = my_preprocessor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a66dc5",
   "metadata": {},
   "source": [
    "ASSIGNMENT: \n",
    "\n",
    "    - Confirm that your preprocessor works by plotting the mean pupil size over the course of a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cef427",
   "metadata": {},
   "source": [
    "\n",
    "## Storing\n",
    "\n",
    "Before we move on to analysis, we store our data. \n",
    "During analysis, we will further manipulate our data. Although we have a clear analysis plan, writing the script for your analysis will be a messy job (espcecially if you do it for the first time!).\n",
    "With our preprocesses data saved, we can start messing with it but easily roll back without having to run the entire preprocessing again (which can be time consuming). Also, it allows you to share your data more readily with collaborators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "from datetime import datetime\n",
    "import os\n",
    "# Each time we save the data, we use a filename that includes the current date and time. This way we won't accidentally overwrite files. If you prefer, you can change the filename.\n",
    "now = datetime.now()\n",
    "filename = \"pd_{}_{}.pickle\".format(os.environ['JUPYTERHUB_USER'], now.strftime(\"%m%d%H%M%S\"))\n",
    "with open(filename, 'wb') as file:\n",
    "    dump(dm, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
